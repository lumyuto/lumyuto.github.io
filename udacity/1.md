为什么要学习统计的基本概念
在本课程的第一部分中，我们会回顾一些统计学基本概念，如何用众数，平均数和中位数衡量数据的中心，如何用值域，IQR，方差/标准差来衡量数据的差异。你很有可能已经熟知所有这些统计概念的定义，那么不妨你可以思考一下：

为什么我们需要多个指标?
这多个指标如何演化而来？
他们之间的优劣是什么？
针对不同的数据集，我应该如何如何选择最适合的指标？
这样的思考会贯穿在整个机器学习纳米学位的课程中，当你学习了多个模型的衡量指标，当你学了多个机器学习的算法。如何比较他们的优劣，如何选择最合适的算法将会是我们一直在讨论的问题。

希望你能够跳出单个算法，去关注整个机器学习的原理。分离训练集和测试集，训练模型，进行交叉验证，最后完成测试 （测试集中能用一次）。 同时了解什么是学习曲线，什么是复杂度曲线，什么是 偏差-方差权衡。

## 数据的差异性 值域 IQR 方差 标准差

受数据采集的影响 受异常值的影响

量化分布形态:

值域 砍掉 首尾的25% Q1 < Q2 < Q3
IQR = Q3 - Q1

OutLier < Q1 - 1.5 * IQR
        > Q3 + 1.5 * IQR

正态分布 双峰分布 均匀分布 可以有相同的IQR

贝塞尔校正 Bessel's correction

var = n -> n-1

##　监督学习简介

## 自动驾驶

```python
from sklearn.naive_bayes import GaussianNB
clf = GaussianNB()
clf.fit(X, Y)
GaussianNB(priors=None)
print(clf.predict([[-0.8, -1]]))
```

!> 崎岖路面的代码 还要看一下

## 朴素贝叶斯

灵敏度是实际有病而且被正确诊断出来的概率 没有放过一个患病的人
但是有一部分正常人被认为是糖尿病人了，这一部分叫做假阳性率

特异度就是实际没病而且被正确诊断的概率 没有冤枉一个没病的人
但是有一部分糖尿病人被认为是正常人了，这一部分叫做假阴性率

敏感性高=漏诊率低 不放过一个坏人
特异性高=误诊率低 不冤枉一个好人

敏感性越高，则越容易鉴定出目标，即越灵敏
特异性只针对特定情况才有阳性反应，即筛选能力强，或者说针对性强

https://www.zhihu.com/question/30750849

![ROC曲线](https://pic3.zhimg.com/80/1f0feded1ade43af0fc4bcba1961a1e2_hd.png)

TP：（真阳性）被正确诊断为患病的病人。
TN：（真阴性）被正确诊断为健康的健康人。
FP：（假阳性）被错误诊断为患病的健康人。
FN：（假阴性）被错误诊断为健康的病人。

敏感性(Sensitivity) = TP/(TP+FN)

特异性(Specificity) = TN/(TN+FP)

![](https://pic2.zhimg.com/80/v2-54494d69bc42f75cc93cd567172adde9_hd.jpg)

查全率(recall) = TP/(TP+FN)

查准率(Precision) = TP/(TP+FP)

![](https://pic4.zhimg.com/80/v2-b5bd7d10e27dfe9738ad88638acca11f_hd.jpg)

Prior 先验
posterior 后验

Prior: P(C) = 0.01
posterior: P(C|Pos) = P(C) * P(Pos|C) 敏感性

P(!C|Pos) = P(!C) | P(Pos|!C) 

--- 

P(A|B) = P(B|A) P(A) / P(B)
```
P(感冒|打喷嚏x建筑工人) 
　　　　= P(打喷嚏x建筑工人|感冒) x P(感冒) 
　　　　/ P(打喷嚏x建筑工人)
```
假定"打喷嚏"和"建筑工人"这两个特征是独立的，因此，上面的等式就变成了
```
P(感冒|打喷嚏x建筑工人) 
　= P(打喷嚏|感冒) x P(建筑工人|感冒) x P(感冒) 
　/ P(打喷嚏) x P(建筑工人)
```

!> 独立的条件: ?

## SVM


> 一段绘图代码 写的很好

```python
import warnings
warnings.filterwarnings("ignore")

import matplotlib 
matplotlib.use('agg')

import matplotlib.pyplot as plt
import pylab as pl
import numpy as np

#import numpy as np
#import matplotlib.pyplot as plt
#plt.ioff()

def prettyPicture(clf, X_test, y_test):
    x_min = 0.0; x_max = 1.0
    y_min = 0.0; y_max = 1.0

    # Plot the decision boundary. For that, we will assign a color to each
    # point in the mesh [x_min, m_max]x[y_min, y_max].
    h = .01  # step size in the mesh
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

    # Put the result into a color plot
    Z = Z.reshape(xx.shape)
    plt.xlim(xx.min(), xx.max())
    plt.ylim(yy.min(), yy.max())

    plt.pcolormesh(xx, yy, Z, cmap=pl.cm.seismic)

    # Plot also the test points
    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]
    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]
    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]
    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]

    plt.scatter(grade_sig, bumpy_sig, color = "b", label="fast")
    plt.scatter(grade_bkg, bumpy_bkg, color = "r", label="slow")
    plt.legend()
    plt.xlabel("bumpiness")
    plt.ylabel("grade")

    plt.savefig("test.png")
    
import base64
import json
import subprocess

def output_image(name, format, bytes):
    image_start = "BEGIN_IMAGE_f9825uweof8jw9fj4r8"
    image_end = "END_IMAGE_0238jfw08fjsiufhw8frs"
    data = {}
    data['name'] = name
    data['format'] = format
    data['bytes'] = base64.encodestring(bytes)
    print image_start+json.dumps(data)+image_end
```

bias 复杂度差
vari 复杂度高

SVM 慢
决策树 过拟合 


## 评估指标
准确率不适合
1. 偏斜的数据
2. 希望多抓一点人 或者少抓一点

准确率 就是 敏感性 

Precision and recall

测错 和 漏测

混淆矩阵

准确率 你说涨 是不是真的涨了
召回率 应该涨的时候 你猜没猜出来

见人就说 你有血光之灾 准确率低
我有灾 你没提醒我 召回率低

Accuracy = (预测正确的样本数)/(总样本数)=(TP+TN)/(TP+TN+FP+FN)

Precision = (预测为1且正确预测的样本数)/(所有预测为1的样本数) = TP/(TP+FP)

Recall = (预测为1且正确预测的样本数)/(所有真实情况为1的样本数) = TP/(TP+FN)

F1 = 2 * (精确率 * 召回率) / (精确率 + 召回率)

